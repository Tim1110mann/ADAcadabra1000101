<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Pre-processing our data</title>
    <link rel="stylesheet" type="text/css" href="style.css">
</head>
<body>
    <header>
        <div class="container">
            <nav>
                <div class="link-1">
                    <ul>
                        <li><a href="https://tim1110mann.github.io/ADAcadabra1000101/about.html">About</a></li>
                    </ul>
                </div>
                <div class = "link-2">
                    <ul>
                        <li><a href="https://tim1110mann.github.io/ADAcadabra1000101/resources.html">Resources</a></li>
                    </ul>
                </div>
                <div class = "link-2">
                    <ul>
                        <li><a href="https://tim1110mann.github.io/ADAcadabra1000101/">Home</a></li>
                    </ul>
                </div>
                <div class = "link-3">
                    <ul>
                        <li><a href="https://tim1110mann.github.io/ADAcadabra1000101/preprocessing.html">Pre-Processing</a></li>
                    </ul>
                </div>
                <div class = "link-4">
                    <ul>
                        <li><a href="https://tim1110mann.github.io/ADAcadabra1000101/supervised-learning.html">Supervised Learning</a></li>
                    </ul>
                </div>
                <div class = "link-5">
                    <ul>
                        <li><a href="https://tim1110mann.github.io/ADAcadabra1000101/unsupervised-learning.html">Unsupervised Learning</a></li>
                    </ul>
                </div>
            </nav>
        </div>
    </header>
    <h1>Pre-processing our data - Features & Character tropes</h1>
    <div class="body-content">
            <p>
                Before we have fun analyzing the data, we should probably get on the same page on the terms of our question of interest. 
                What are the actor features do we want to analyse? 
                What character tropes are we using for our categories?
            </p>
            <br>
            <h2>Character Tropes</h2>
            <p>
                As mentionned in our <a href="https://tim1110mann.github.io/ADAcadabra1000101/about.html">About</a> page we are using the dataset provided by the CMU Movie Summary Corpus, collected by David Bamman, Brendan O'Connor, and Noah Smith. 
                This dataset provides us with lots of interesting data on more than 42 000 movies such as the actors and their roles in each movie, their box office numbers, the movie genres and more.
                Let's start by determining our character tropes from this data.                
            </p>
            <p>
                The CMU Corpus provides us with 72 character tropes, based of <a href="https://tvtropes.org/">TVTropes.org</a>, with 501 characters manually categorised in each.
                As such, we narrow our focus on these 501 characters.
                We can view the distribution of these characters per trope in the graph below.
                <img src="preprocessing_graphs/characters_per_trope.png" alt="Characters per Trope">
            </p>
            <p>
                Our first reaction seeing this graph was "Wow, there are a lot of crazy jealous guys in movies!" followed by "Why does no one want to be a classy cat burglar?".
                Jokes aside, the graph shows how unbalanced the distribution of characters per trope in our initial dataset. 
                Indeed, with only one or two characters per trope at times, it would be quite impossible to come to unbiased conclusions regarding these tropes. 
                It would be quite easy for us to say that if you don't have the same features as the actor playing the classy cat burglar trope, your dreams of playing that trope are as good as dead.
                Luckily for you (and for us), we decided against this easy way out.  
            </p>
            <br>
            <p>
                Using our movie knowledge and the descriptions provided by <a href="https://tvtropes.org/">TVTropes.org</a>, we regrouped similar tropes together, creating larger archetypes. 
                Some tropes were easy to group together, such as the <code>klutz</code> and the <code>ditz</code>. 
                We tried to come up with names that best encapsulated the different features of these combined tropes.
                All in all, we utimately came up with 16 unique character archetypes. From now on, when we will refer to <i>character tropes</i>, we will refer to these 16 archetypes:
                <ul>
                    <li> <code> skilled_badass </code> </li>
                    <li> <code> loser </code> </li>
                    <li> <code> laidback_freebird </code> </li>
                    <li> <code> jock </code> </li>
                    <li> <code> charismatic_charmer </code> </li>
                    <li> <code> respected_leader </code> </li>
                    <li> <code> crazy_fighter </code> </li>
                    <li> <code> dumb_and_clumsy </code> </li>
                    <li> <code> shallow_and_popular </code> </li>
                    <li> <code> old_wise_quirky </code> </li>
                    <li> <code> sidekick </code> </li>
                    <li> <code> emotional_damage </code> </li>
                    <li> <code> evil_character </code> </li>
                    <li> <code> mean_officer </code> </li>
                    <li> <code> tech_genius </code> </li>
                </ul>
            </p>
            <br>
            <p>
                We can plot the number of characters per trope to observe their distribution as we did before.
                <img src="preprocessing_graphs/characters_per_newgrped_tropes.png" alt="Characters per (New) Tropes">
            </p>
            <p>
                There is now at least a dozen characters per trope, giving us a much better sample size to base our analysis on.
            </p>
            <h2>Actor Features</h2>
            <h4>Height, Age, Gender & Ethnicities</h4>
            <p> 
                With our tropes defined and out of the way, we need to define our actor features. 
                The CMU Corpus gives us a few interesting actor characteristics that we will explore such as <code>ActorHeight</code>, <code>ActorAge</code>, <code>ActorGender</code> and <code>ActorEthnicity</code>.
            </p>
            <br>
            <p>
                As we explored <code>ActorEthnicity</code>, we slowly realised that this variable would be unusable for our data analysis. 
                Indeed, we observed more than 30% of missing data for this variable <i>(anything over 10% increases the likelihood of biased results)</i> and we could not find any suitable datasets online to complete these missing values.
                The ethnicities defined in the CMU Corpus were extremely precise, such as <code>Afro Trinidadians and Tobagonians</code> or <code>Ashkenazi Jews</code>. 
                A lot of the ethnicities defined in the data seemed to fall also under the umbrella of nationality, with labels like <code>Korean American</code>. 
            </p>
            <p>
                At first, we tried to simplify these ethnicities, in an attempt to group them together as we did with the tropes earlier. 
                But this raised a clear ethical question, who are we to say that an actor identifying as Korean American can be reduced to either just Korean or just American?
            </p>
            <p>
                As such, with all of these issues, we decided to remove this variable from our analysis, simplifying our analysis, and saving us from the burden of ethical dilemnas!
            </p>
            <br>
            <p> 
                Let us now explore <code>ActorHeight</code>, <code>ActorAge</code> and <code>ActorGender</code>. 
                These variables did not have nearly as many missing values as <code>ActorEthnicity</code> and as such, we were able to complete them manually.
                <img src="preprocessing_graphs/ActorHeight - ActorAge by Gender.png">
            </p>
            <p>
                From the plots, we observe that female actors are usually much younger than their male counterparts <i>(and smaller but this is probably more a matter of biology than casting preference)</i>.
                Could this be our first clue for our analysis? The only way for you to find out is keep reading...
            </p>
            <br>
            <h4>Facial Landmarks & Encodings</h4>
            <p>
                Having <code>Height</code>, <code>Age</code> and <code>Gender</code> is all well and good but we probably won't go very far with just these features to qualify an actor <i>(it would be quite reductive to qualify Brad Pitt as an 1.8m tall, 59 year-old man)</i>.
                No... we need something more... something more substantial to properly characterise each actor.
            </p>
            <p>
                Have you ever had that moment when you looked at your friend and you said to yourself, "You would make a fantastic protagonist"? 
                Or that moment after a movie screening when you just say "That character was perfectly cast". 
                Think Draco Malfoy played by Tom Felton in Harry Potter, or Joffrey Baratheon played by Jack Gleeson in Games of Thrones. 
                There is just something about them that perfectly match with their <i>(hypothesised in the case of your friend)</i> roles. 
                It can't be their personalities because, well, you don't know the actors <i>(unless you do, in that case could you ask Tom to sign my Philosopher's Stone book for me?)</i>.
                And with today's means, it is highly common for actors to change their body shape and haircut for the role they're casted in. 
                However, there is one thing they can not drastically alter: their face.
            </p>
            <br>
            <p>
                As such, we decided to analyse the face of each actor in our dataset, characterising them as facial encodings and landmarks.
                We extract facial images of the 347 actors playing the 501 characters (some actors play different roles) from <a href="https://www.themoviedb.org/">The Movie Database (TMDB)</a>.
                A new dataset named <code>actor_images.csv</code> is created, containing the actor's name and their corresponding image stored as URL with its width and height.
            </p>
            <br>
            <p>
                Using the <code>face_recognition</code> and OpenCV libraries, we extract the facial landmarks and encodings of each image.
            </p>
            <p>
                The facial landmarks are a set of 68 coordinates (x and y), corresponding to the implacement of human face specific landmarks such as eyes, nose, eyebrows, lips and chin in the image.
                <img src="68 Facial points ADA.jpg">
            </p>
            <br>
            <p>
                On the other hand, face encodings are a set of 128 encodings, specific to a person. As explained in <a href="https://www.researchgate.net/publication/331769278_Surveillance_system_with_motion_and_face_detection_using_histograms_of_oriented_gradients">Ng et al.,2019</a> :
            </p>
            <p>
                <i>"In  the  face  encoding  and  feature  extraction  step,  deep  learning is  implemented  in  this  step  to determine which part of the  face is  important to be measured for the face recognition process. The  deep convolutions  neural  network  is  being  trained  by  loading  a  training  face  image  of  a  known  person,  load another picture of the  same known person, and  load a picture of a  totally different person,  then the neural network tweak accordingly based  to the result. After  lots of repeating training, the neural network learns to reliably generate 128 measurements for each person."</i>
            </p>
            <br>
            <p>
                Our main interest concerning these facial features is to compare actors between each other, to identify which actors, associated with their respective role and trope, would cluster together. 
                We will use the facial landmarks to compare the ratios between facial features. 
                In other word, we will not compare the size of actors' noses but rather we will compare the proportion of the different distinctive facial features relative to the actor's face.
                For example, an actor may appear to have large eyes due to their small face while in absolute their eyes are averaged sized.
                We identify various distinctive facial features, <code>Eye Distance</code>, <code>Eye Positon</code>, <code>Nose Length</code>, <code>Nose Width</code>, <code>Eyebrow Length</code>, <code>Face Shape</code> and <code>Cheek Bones</code>.
                Let us look which of these facial features are independent by observing their distributions.
                <img src="preprocessing_graphs/Distribution of Facial Landmarks.png">
            </p>
            <p>
                Three parameters jump out as variables of interest for us.
                We observe that the <code>Nose Length</code> is normally distributed, whereas the <code>Eye Distance</code> and <code>Nose Width</code> are skewed towards the right and left, respectively.
                In terms of correlation, <code>Eye Distance</code> and <code>Nose Length</code> are not correlated, <code>Nose Width</code> and <code>Eye Distance</code> weakly positively correlated, and <code>Nose Width</code> and <code>Nose Length</code> weakly negatively correlated. 
                This means that we can consider those three parameters, <code>Eye Distance</code>, <code>Nose Length</code>, <code>Nose Length</code> as independant of each other and use them for our analysis as such.
            </p>
            <br>
            <p>
                While facial landmarks are used to compared the proportions of actors' facial features, we will use Facial Encodings to compare actors between each other.
                Indeed, we calculate the Euclidean Distance between facial encodings to get a sense of how closely actors ressemble each other.
                The higher the calculated value, the further apart they are.
            </p>
            <br>
            <p>
                And so,to conclude we identified a set of features to define our actors.:
                <ul>
                    <li> <code> ActorGender </code> </li>
                    <li> <code> ActorAge </code> </li>
                    <li> <code> ActorHeight </code> </li>
                    <li> <code> Facial Landmarks </code> </li>
                    <li> <code> Facial Encodings </code> </li>
                </ul>
            <br>
            </p>
            <p>
                We can now combine this set of features with our 16 unique character tropes to start chipping away at the answer of our main question, <b>"Which features define particular character tropes?"</b>, locked behind a set of doors.
                As we stand in front of these locked doors, having completed the first step of pre-processing, we say the magic words: <b><i>Open Sesame</i></b>.
                And to our surprise, unlike Ali Baba in front of the thieves' den, two paths open up to us:
            </p>
            <h3> <a href="https://tim1110mann.github.io/ADAcadabra1000101/supervised-learning.html">Supervised Learning</a> or <a href="https://tim1110mann.github.io/ADAcadabra1000101/unsupervised-learning.html">Unsupervised Learning</a></h3>
            <p>
                Which should we choose? Why not both? But more importantly... which path will you choose to read next?
            </p>
            <br>
    </div>
</body>
</html>
