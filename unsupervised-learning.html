<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Unsupervised Learning</title>
    <link rel="stylesheet" type="text/css" href="style.css">
</head>
<body>
    <header>
        <div class="container">
            <nav>
                <div class="link-1">
                    <ul>
                        <li><a href="https://tim1110mann.github.io/ADAcadabra1000101/about.html">About</a></li>
                    </ul>
                </div>
                <div class = "link-2">
                    <ul>
                        <li><a href="https://tim1110mann.github.io/ADAcadabra1000101/">Home</a></li>
                    </ul>
                </div>
                <div class = "link-3">
                    <ul>
                        <li><a href="https://tim1110mann.github.io/ADAcadabra1000101/preprocessing.html">Pre-Processing</a></li>
                    </ul>
                </div>
                <div class = "link-5">
                    <ul>
                        <li><a href="https://tim1110mann.github.io/ADAcadabra1000101/supervised-learning.html">Supervised Learning</a></li>
                    </ul>
                </div>
                <div class = "link-4">
                    <ul>
                        <li><a href="https://tim1110mann.github.io/ADAcadabra1000101/unsupervised-learning.html">Unsupervised Learning</a></li>
                    </ul>
                </div>
                <div class = "link-6">
                    <ul>
                        <li><a href="https://tim1110mann.github.io/ADAcadabra1000101/conclusion.html">Conclusion</a></li>
                    </ul>
                </div>
            </nav>
        </div>
    </header>
    <h1>Unsupervised Learning</h1>
    <div class="body-content">
        <p>
            Welcome to the Unsupervised Learning chapter! 
            You chose correctly (don't say that to the <a href="https://tim1110mann.github.io/ADAcadabra1000101/supervised-learning.html">Supervised Learning</a> narrator, he gets jealous easily...). 
            Join us as we opt for a more mysterious approach, keeping our data unlabelled and trying to observe patterns, courtesy of the different clustering methods we will use.
            That means that we can keep pre-defined character tropes on the back-burner for now and, if it all goes swimmingly, we'll find them again at the end of this chapter.
            Let's dive in!
        </p>
        <br>
        <h2>Clusters, clusters and more... clusters!</h2>
        <p>
            As we believe that an actor's face is their most determinant feature, we will only focus on the facial landmarks and encodings to obtain the clusters.
            We will start off with just the facial encodings.
            Indeed, we wanted to see whether characters, played by their respective actors, will naturally cluster together based on their encodings. 
            As a quick reminder, the facial encodings are a set of 128 measurements processed by the face recognition algorithm that is unique to each individual.
            As such, it is a much better metric to diffenriate actors between each other than the facial landmarks.
        </p>
        <br>
        <p>
            Now let's get down to the nitty gritty and fun details.
        </p>
        <p>
            We use the Euclidean distance between encodings as a metric of ressemblance between actors, and in consequence characters.
            Our default threshold that defines whether two faces ressemble each other is 0.6 in terms of euclidean distance.
            In other words, if the euclidean distance between actors is around 1, the actors do not ressemble each other.
        </p>
        <p>
            We chose hierarchical clustering as our method for grouping. This entails cluster maps and dendogram functions from the Seaborn Library.
            As such, we built out our cluster map based on Euclidean distance, using the "complete" function to define the distance between two clusters. 
            That means that the distance between cluster <code>u</code> and the cluster <code>v</code> is defined as the maximum distance between a point in <code>u</code> and a point in <code>v</code>.
            <img src="UnsupervisedLearning_graphs/HeatMap Characters.png">
            <img src="UnsupervisedLearning_graphs/Dendogram_characters.png">
        </p>
        <br>
        <p>
            We obtain 4 clusters, yay! What does this mean concretely though, you ask? Good question!
        </p>
        <p>
            We say that a trope is represented by a cluster when at least 50% of characters of that trope are present in said cluster.
            <img src="UnsupervisedLearning_graphs/Tropes composition pie-1.png">
            <img src="UnsupervisedLearning_graphs/Tropes composition pie-2.png">
            <img src="UnsupervisedLearning_graphs/Tropes composition pie-3.png">
            <img src="UnsupervisedLearning_graphs/Tropes composition pie-4.png">
        </p>
        <br>
        <p>
            Let us analyse which tropes are composed of which cluster:
            <ul>
                <li>Cluster 1 is the smallest and does not contain a majority of any trope.</li>
                <li>Cluster 2 is particularly interesting, differentiating itself from other clusters as we observe only 3 tropes being majoritarily represented.</li>
                <li>Cluster 3 and 4 contain similar tropes and ressemble each other.</li>
            </ul>
        </p>
        <p>
            So, of the 16 tropes we identified in our <a href=""https://tim1110mann.github.io/ADAcadabra1000101/preprocessing.html">pre-processing </a> step, 13 of them cluster together in a specific cluster.
            Interesteing stuff, right? Let's zoom in and dive into the inter- and intra-cluster analysis.
        </p>
        <br>
        <p>
            The cluster C1 is very interesting. 
            It is the cluster with the less intra-cluster variation compared to the complete data variation but it has no trope associated with it. 
            This suggests that characters from this cluster have very similar encodings, facial traits, but that those traits are not representative of any trope. F
            urther investigations leads to the conclusion that this cluster is composed uniquely of black people and comprises all the black people we have in the dataset. 
            It indicates that we have a bias that separates black people from white people, and that for our algorithm this difference is more important than the difference between tropes.
            <img src="UnsupervisedLearning_graphs/ActorsC1.png">
        </p>
        <p>
            However, as Cluster 1 does not represent any of the tropes, we do not include it in further analysis.
        </p>
        <br>
        <p>
            Cluster 2 represents more than 80% of the <code>shallow_and_popular</code> trope and more than 50% of the <code>emotional_damage</code> and <code>dumb_and_clumsy</code> tropes.
            We observe that this Cluster is mainly represented by women. 
            It seems like these tropes are primarily played by women. 
            A quick look at the gender representation by cluster confirms this. It's another clue, we're getting closer!
            <img src="UnsupervisedLearning_graphs/GenderinClusters.png">
        </p>
        <br>
        <p>
            For cluster 3 and 4, we wanted to see if redoing the clustering on these clusters would allow us to further group tropes but no dice. 
            None of the sub-clusters contained any majority of any of the tropes.
            As such, we keep the clusters 3 and 4 as they are.
        </p>
        <p>
            We identify the following tropes <i>(more than 50% of the trope represented in the cluster)</i> for each cluster.
            <ul>
                <li>C3: <code>charismatic_charmer</code>, <code>laidback_freebird</code>, <code>sidekick</code> and <code>crazy_jealous_guy</code></li>
                <li>C4: <code>crazy_fighter</code>, <code>mean_officer</code>, <code>skilled_badass</code>, <code>old_wise_quirky</code>, <code>respected_leader</code> and <code>evil_character</code></li>
            </ul>
        </p>
        <br>
        <h2>Each cluster's very own encodings</h2>
        <p>
            Now, we analyse the encodings for each cluster of interest, defined henceforth as C2, C3 and C4.
            As such, for example if encoding <code>x</code> is very specific to C2 and differ from other clusters, we decide that this particular encoding can be used to describe people belonging to Cluster 2.
            Let us find the most relevant encodings per cluster.
        </p>
        <p>
            To be able to compare all the encodings, we standardized them using Z-score normalization and we choose robust statistics to describe them i.e their median and median absolute deviation (MAD).
            Indeed, to find the most relevant encodings per cluster, we searched for the ones:
            <ul>
                <li>which varied less compared to their variation across all the data.</li>
                <li>which are far from the other clusters' values.</li>
                <li>which deviate the most compared to the data mean.</li>
            </ul>
        </p>
        <br>
        <p>
            To this end, we computed:
            <ul>
                <li>each encoding's MAD ratio, which is equal to: (encoding's MAD intra-cluster)/(encoding's MAD over the complete data)</li>
                <li>each encoding's minimum distance i.e the minimum distance between the median of this encoding for a given cluster and the median of this same encoding for the other clusters</li>
                <li>each encoding's median cluster, plotted against its standardized distribution over the complete data</li>
            </ul>
        </p>
        <br>
        <p>
            We can observe this in our scatter plot below.
            <iframe src="UnsupervisedLearning_graphs/EncodingsScatterplot.html" width=100% height="600"></iframe>
        </p>
        <p>
            We can zoom in to better visualise our distribution by filtering our encodings with a MAD ratio smaller than 1.
            <iframe src="UnsupervisedLearning_graphs/EncodingsScatterplot_ratiovariation1(zoom).html" width=100% height="600"></iframe>
        </p>
        <br>
        <p>
            From the scatter plot, we hand-picked the following most relevant encodings for each cluster using the criteria mentionned above.
            <ul>
                <li>Cluster 2: 77, 85, 63, 127, 89, 9, 81 and 72</li>
                <li>Cluster 3: 28, 93, 107, 10, 78 and 53</li>
                <li>Cluster 4: 75, 24, 79, 98, 19 and 40</li>
            </ul>
        </p>
        <br>
        <p>
            To confirm our results, we can visualise the distribution for each most relevant encoding we hnandpicked using a violin plot.
            <img src="UnsupervisedLearning_graphs/ViolinPlots.png">
        </p>
        <p>
            We observe that most of the encodings have non-overlapping 95% confidence intervals (CI) with the other clusters' 95% CI. 
            This is good news for us as it means that the difference is statistically significative <i>(always a yay when we get to say that)</i>.
            Hence, this gives more confidence in our results and in the fact that some tropes have their own encodings, and surely require such unique encodings to be accepted as individual tropes.
        </p>
        <p>
            I think we're onto something now... Let's keep digging.
        </p>
        <br>
        <h2>From encodings to facial landmarks</h2>
        <p>
            Having found the specific encodings for each cluster, we determine the centroid of each cluster and define it as the general representation of characters associated to that cluster.
        </p>
        <p>
            Although the encodings are very useful to compare the similarities between actor faces and allows us to cluster the characters together, they still remain quite mysterious.
            Indeed, it is hard to understand what these encodings represent physically. Thankfully, we have our landmarks to the rescue!
            We will use the proportions obtained by the facial landmarks to "translate" what really defines each cluster.
            For example, for Cluster 1, although it may not contain a specific trope, upon further digging, we observe that C1 contains a specific ethnicity: <code>black</code>.
            This explains why we observe the nose width, courtesy of our landmarks, of said cluster differs from the other clusters.
        </p>
        <br>
        <p>
            So we use 7 different proportions of facial features we plotted in our <a href="https://tim1110mann.github.io/ADAcadabra1000101/preprocessing.html">pre-processing step</a>: 
            <code>Eye Distance</code>, <code>Eye Position</code>, <code>Nose Length</code>, <code>Eyebrow Length</code>, <code>Face Shape</code> and <code>Cheek Bones</code>.
            <img src="UnsupervisedLearning_graphs/Violinplots_landmarks.png">
        </p>
        <p>
            We notice that Cluster 2 is particularly distinguishable in all facial features compared to C3 and C4.
            On the other hand, C3 and C4 seem quite similar in terms of distribution of the facial features.
        </p>
        <br>
        <p>
            We can finish things off by displaying images of the actors that best represent each cluster of interest i.e. C2, C3 and C4.
            As such, we are quite literally putting a face to each cluster's own tropes and facial features!
        </p>
        <p>
            To no one's surprise, we have three images of female actors for our representation of C2.
            <img src="UnsupervisedLearning_graphs/ActorsC2.png">
        </p>
        <p>
            From our analysis, they played mostly the <code>shallow_and_popular</code>, <code>emotional_damage</code> and <code>dumb_and_clumsy</code> tropes.
        </p>
        <br>
        <p>
            For C3, maybe beards could be a defining feature <i>(note to self: grow a beard)</i>!
            <img src="UnsupervisedLearning_graphs/ActorsC3.png">
        </p>
        <p>
            They mainly represented the <code>charismatic_charmer</code>, <code>laidback_freebird</code>, <code>sidekick</code> and <code>crazy_jealous_guy</code> tropes.
        </p>
        <br>
        <p>
            And for Cluster 4, we have these three actors images:
            <img src="UnsupervisedLearning_graphs/ActorsC4.png">
        </p>
        <p>
            And to finish things off, the actors in C4 represented a wide array of character tropes, mainly playing the <code>crazy_fighter</code>, <code>mean_officer</code>, <code>skilled_badass</code>, <code>old_wise_quirky</code>, <code>respected_leader</code> and <code>evil_character</code> tropes.
        </p>
        <br>
        <p>
            In summary, by allowing the data to cluster by itself, we were able to identify three clusters of interest <i>(C2, C3 and C4)</i>. 
            Each cluster represented their own tropes and had their own most relevant encodings and landmarks. 
            We're edging closer to an answer to our overarching question, I'm getting goosebumps just thinking about it!
        </p>
        <p>
            I'll let you hop over to the Supervised Learning chapter now to continue on our data story, we wouldn't want the narrator over there feeling too lonely.
        </p>
        <h3> <a href="https://tim1110mann.github.io/ADAcadabra1000101/supervised-learning.html">Supervised Learning</a></h3>
        <p>
            You're still here? Wait... no... that means you chose to read my chapter in second?! I can't believe it...
        </p>
        <p>
            Fine then. See if I care. Go on, go over to the final chapter.
        </p>
        <h3> <a href="https://tim1110mann.github.io/ADAcadabra1000101/conclusion.html">Conclusion</a></h3>
    </div>
</body>
</html>
