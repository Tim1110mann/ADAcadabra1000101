<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Causal Analysis</title>
    <link rel="stylesheet" type="text/css" href="style.css">
</head>
<body>
    <header>
        <div class="container">
            <nav>
               <div class="link-1">
                    <ul>
                        <li><a href="https://tim1110mann.github.io/ADAcadabra1000101/about.html">About</a></li>
                    </ul>
                </div>
                <div class = "link-2">
                    <ul>
                        <li><a href="https://tim1110mann.github.io/ADAcadabra1000101/">Home</a></li>
                    </ul>
                </div>
                <div class = "link-3">
                    <ul>
                        <li><a href="https://tim1110mann.github.io/ADAcadabra1000101/preprocessing.html">Pre-Processing</a></li>
                    </ul>
                </div>
                <div class = "link-5">
                    <ul>
                        <li><a href="https://tim1110mann.github.io/ADAcadabra1000101/causal-analysis.html">Causal Analysis</a></li>
                    </ul>
                </div>
                <div class = "link-4">
                    <ul>
                        <li><a href="https://tim1110mann.github.io/ADAcadabra1000101/unsupervised-learning.html">Unsupervised Learning</a></li>
                    </ul>
                </div>
                <div class = "link-6">
                    <ul>
                        <li><a href="https://tim1110mann.github.io/ADAcadabra1000101/conclusion.html">Conclusion</a></li>
                    </ul>
                </div>
            </nav>
        </div>
    </header>
    <h1>Supervised Learning</h1>
    <div class="body-content">
        <p>
            Welcome to Causal Analysis!
        </p>
        <p>
            I hope the <a href="https://tim1110mann.github.io/ADAcadabra1000101/unsupervised-learning.html">Unsupervised Learning</a> narrator didn't say anything too mean to you while you were over there.
            Oh, you came to me first? That's awfully kind of you :).
            Anyway, enough blabbing around, let's dive straight in!
        </p>
        <br>
        <p>
            From our <a href="https://tim1110mann.github.io/ADAcadabra1000101/preprocessing.html">pre-processing</a>, we defined the key terms of our main question, the<b>features</b> and the <b>character tropes</b>.
            In this chapter, we are opting for a more causal approach.
            In other words, given an input <code>X</code>, we can find the output <code>y</code> via a function <code>f(X)</code>, with <code>f(X)</code> being the main mystery.
        </p>
        <p>
            We can apply this approach to our case and define our input <code>X</code> as the set of features we defined a chapter ago and our output <code>y</code> as our 16 unique character tropes.
            We would like to "learn" the function <code>f</code> that links the two such that <code>f(X) = y</code>.
            Who knows? We might even be able to have fun after having found this function, like figure out what kind of trope I would play!
        </p>
        <br>
        <p>
            As we have a discrete y, each character trope represents a separate and independent category, we have to go with classification.
            We will go through various methods to find our <code>f(X)</code>.
            Let's start with Decision Trees!
        </p>
        <h2>A Tree of Decisions</h2>
        <p>
            We had the choice between kNN or Decisions Trees as our preferred algorithm of classification. 
            We played around with both, testing them on our features and after seeing our results we opted for a decision tree. Yay!
            Now that we planted our tree, what's so special about it?
        </p>
        <p>
            To answer briefly, the <b>F1-score</b>.
        </p>
        <p>
            The F1-score is a measure of predictive performance. 
            And so in our case, the higher the F1-score, the better our classification algorithm can find a pattern of features that best describe our tropes.
            We compute the F1-score for each of our 16 character tropes and get the following table:
            <table border="1">
                <thead>
                    <tr>
                        <th>Tropes</th>
                        <th>F1-Score</th>
                    <\tr>
                </thead>
                <tbody>
                    <tr>
                        <td><code>charismatic_charmer</code></td>
                        <td>0.36</td>
                    <\tr>
                    <tr>
                        <td><code>crazy_fighter</code></td>
                        <td>0.13</td>
                    </tr>
                    <tr>
                        <td><code>crazy_jealous_guy</code></td>
                        <td>0.10</td>
                    </tr>
                    <tr>
                        <td><code>dumb_and_clumsy</code></td>
                        <td>0.26</td>
                    </tr>
                    <tr>
                        <td><code>emotional_damage</code></td>
                        <td>0.24</td>
                    </tr>
                    <tr>
                        <td><code>evil_character</code></td>
                        <td>0.05</td>
                    </tr>
                    <tr>
                        <td><code>jock</code></td>
                        <td>0.26</td>
                    </tr>
                    <tr>
                        <td><code>laidback_freebird</code></td>
                        <td>0.50</td>
                    </tr>
                    <tr>
                        <td><code>loser</code></td>
                        <td>0.09</td>
                    </tr>
                    <tr>
                        <td><code>mean_officer</code></td>
                        <td>0.09</td>
                    </tr>
                    <tr>
                        <td><code>old_wise_quirky</code></td>
                        <td>0.23</td>
                    </tr>
                    <tr>
                        <td><code>respected_leader</code></td>
                        <td>0.21</td>
                    </tr>
                    <tr>
                        <td><code>shallow_and_popular</code></td>
                        <td>0.39</td>
                    </tr>
                    <tr>
                        <td><code>sidekick</code></td>
                        <td>0.15</td>
                    </tr>
                    <tr>
                        <td><code>skilled_badass</code></td>
                        <td>0.13</td>
                    </tr>
                    <tr>
                        <td><code>tech_genius</code></td>
                        <td>0.15</td>
                    </tr>
                </tbody>
            </table>
        </p>
        <p>
            As said above, a high F1-score means that the model has a good balance at not only identifying most of the true tropes but also maintaining a low rate of false positives.
            We can observe <code>laidback_freebird</code> as a trope with seemingly distinctive features.
        </p>
        <p>
            As such, to select the tropes that are best described by our model, we set a F1-score threshold of <b>0.15</b>.
            This allows us to focus our energy on the tropes where the link between features and trope is strong and statistically significant, potentially leading to more confident insights into Hollywood's typecasting patterns.
            We select the following tropes:
            <ul>
                <li><code>charimastic_charmer</code></li>
                <li><code>jock</code></li>
                <li><code>dumb_and_clumsy</code></li>
                <li><code>emotional_damage</code></li>
                <li><code>laidback_freebird</code></li>
                <li><code>old_wise_quirky</code></li>
                <li><code>shallow_and_popular</code></li>
                <li><code>respected_leader</code></li>
            </ul>
        </p>
        <br>
        <h2>Individual Model Training</h2>
        <p>
            We now have 8 character tropes of interest.
            After a multi-class approach in the step above, I think these each tropes are craving a bit of one-on-one attention.
        </p>
    </div>
</body>
</html>
